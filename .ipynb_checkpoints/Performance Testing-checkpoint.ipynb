{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb968542-c1dd-4434-9a3b-6f80ca4ec51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython jupyter numpy pandas scikit-learn sklearn keras tensorflow matplotlib\n",
    "!pip install ipython jupyter numpy pandas scikit-learn sklearn keras matplotlib\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install ipython jupyter\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-gpu\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install -U pip\n",
    "!pip install -U matplotlib\n",
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ea2ee-d844-4ea3-bb05-6b71a43c7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def convert_to_logs(input_dir, output_dir):\n",
    "    if not os.path.exists(input_dir):\n",
    "        print(f\"Input directory '{input_dir}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".txt\"):\n",
    "                source_file = os.path.join(root, filename)\n",
    "                target_file = os.path.join(output_dir, filename.replace(\".txt\", \".log\"))\n",
    "                shutil.copyfile(source_file, target_file)\n",
    "                print(f\"Converted {source_file} to {target_file}\")\n",
    "\n",
    "# Define paths\n",
    "training_data_dir = '/home/user/adfa-ld/training_data'\n",
    "validation_data_dir = '/home/user/adfa-ld/validation_data'\n",
    "attack_data_dir = '/home/user/adfa-ld/attack_data'\n",
    "\n",
    "# Convert logs\n",
    "convert_to_logs(training_data_dir, '/var/log/adfa-la-training')\n",
    "convert_to_logs(validation_data_dir, '/var/log/adfa-la-validation')\n",
    "convert_to_logs(attack_data_dir, '/var/log/adfa-la-attack')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c432280-9533-49fc-8d99-01d3deef650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def preprocess_adfa_ld(data_dir, output_dir):\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Data directory '{data_dir}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                src_file = os.path.join(root, file)\n",
    "                dest_file = os.path.join(output_dir, os.path.relpath(src_file, data_dir))\n",
    "                dest_dir = os.path.dirname(dest_file)\n",
    "                os.makedirs(dest_dir, exist_ok=True)\n",
    "                shutil.copy(src_file, dest_file)\n",
    "                print(f\"Copied {src_file} to {dest_file}\")\n",
    "\n",
    "base_dir = \"/home/user/adfa-ld\"\n",
    "preprocess_adfa_ld(os.path.join(base_dir, \"attack_data\"), os.path.join(base_dir, \"preprocessed/attack_data\"))\n",
    "preprocess_adfa_ld(os.path.join(base_dir, \"training_data\"), os.path.join(base_dir, \"preprocessed/training_data\"))\n",
    "preprocess_adfa_ld(os.path.join(base_dir, \"validation_data\"), os.path.join(base_dir, \"preprocessed/validation_data\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99b0d7-a3bd-4528-ace3-657da9b1084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "log_directory = '/var/log/adfa-la-training'  # Update this to the correct log directory\n",
    "\n",
    "def read_log_files(log_directory):\n",
    "    if os.path.exists(log_directory):\n",
    "        for filename in os.listdir(log_directory):\n",
    "            if filename.endswith(\".log\"):  # Check if the file ends with .log\n",
    "                file_path = os.path.join(log_directory, filename)\n",
    "                with open(file_path, 'r') as file:\n",
    "                    for line in file:\n",
    "                        print(line)\n",
    "    else:\n",
    "        print(f\"Directory '{log_directory}' does not exist.\")\n",
    "\n",
    "def read_netflow_files(directory):\n",
    "    data_frames = []\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Directory '{directory}' does not exist.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if directory doesn't exist\n",
    "\n",
    "    print(f\"Reading files from directory: {directory}\")\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            print(f\"Reading file: {filepath}\")\n",
    "            df = pd.read_csv(filepath, delimiter=\"\\t\", header=None)  # Adjust delimiter and header as necessary\n",
    "            data_frames.append(df)\n",
    "\n",
    "    if not data_frames:\n",
    "        print(\"No .txt files found in the directory.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no files are found\n",
    "\n",
    "    return pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Update the directory path\n",
    "directory = \"/home/user/adfa-la/netflow_ids_label/netflow_ids_label/Training_Data_Master\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    log_directory = '/var/log/adfa-la-training'  # Ensure this path is correct\n",
    "    read_log_files(log_directory)\n",
    "\n",
    "    df = read_netflow_files(directory)\n",
    "    if not df.empty:\n",
    "        print(df.head())  # Print the first few rows of the concatenated DataFrame to verify\n",
    "\n",
    "        def process_data(df):\n",
    "            print(\"Data Overview:\")\n",
    "            print(df.info())\n",
    "            print(\"\\nBasic Statistics:\")\n",
    "            print(df.describe())\n",
    "\n",
    "            df['is_suspicious'] = df[1] > 10000  # Custom rule for identifying large transfers\n",
    "            suspicious_traffic = df[df['is_suspicious']]\n",
    "\n",
    "            print(\"\\nSuspicious Traffic:\")\n",
    "            print(suspicious_traffic)\n",
    "\n",
    "        process_data(df)\n",
    "    else:\n",
    "        print(\"No data to process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13efcbfd-8b14-439b-a1ba-e8f6a5cbab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alerts_log = '/var/ossec/logs/alerts/alerts.log'\n",
    "\n",
    "def parse_alerts(alerts_log):\n",
    "    if not os.path.exists(alerts_log):\n",
    "        print(f\"Alerts log file '{alerts_log}' does not exist.\")\n",
    "        return []\n",
    "\n",
    "    with open(alerts_log, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    print(\"Lines read from log file:\")\n",
    "    print(lines)\n",
    "\n",
    "    alerts = [line.strip() for line in lines if \"OSSEC\" in line]\n",
    "    return alerts\n",
    "\n",
    "def analyze_alerts(alerts):\n",
    "    df = pd.DataFrame(alerts, columns=[\"Alert\"])\n",
    "    df['Type'] = df['Alert'].apply(lambda x: 'Attack' if 'attack' in x.lower() else 'Normal')\n",
    "\n",
    "    print(\"DataFrame:\")\n",
    "    print(df)\n",
    "\n",
    "    alert_counts = df['Type'].value_counts()\n",
    "\n",
    "    print(\"Alert counts:\")\n",
    "    print(alert_counts)\n",
    "\n",
    "    if not alert_counts.empty:\n",
    "        alert_counts.plot(kind='bar')\n",
    "        plt.title('OSSEC Alert Counts')\n",
    "        plt.xlabel('Alert Type')\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No alerts to plot.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    alerts = parse_alerts(alerts_log)\n",
    "    if alerts:\n",
    "        analyze_alerts(alerts)\n",
    "    else:\n",
    "        print(\"No alerts to analyze.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e4b00-32d2-4b50-b665-d2e7f84f6a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_ids(train_data, train_labels, test_data, test_labels):\n",
    "    # Replace with actual IDS training and prediction\n",
    "    ids_predictions = np.random.randint(2, size=len(test_labels))  # Example random predictions\n",
    "\n",
    "    cm = confusion_matrix(test_labels, ids_predictions)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "    precision = precision_score(test_labels, ids_predictions)\n",
    "    recall = recall_score(test_labels, ids_predictions)\n",
    "    f1 = f1_score(test_labels, ids_predictions)\n",
    "    accuracy = accuracy_score(test_labels, ids_predictions)\n",
    "\n",
    "    return tpr, fpr, precision, recall, f1, accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = np.random.randn(1000, 10)  # Example data matrix\n",
    "    labels = np.random.randint(2, size=1000)  # Example binary labels\n",
    "\n",
    "    k = 5\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True)\n",
    "\n",
    "    tprs, fprs, precisions, recalls, f1s, accuracies = [], [], [], [], [], []\n",
    "\n",
    "    for train_index, test_index in skf.split(data, labels):\n",
    "        train_data, test_data = data[train_index], data[test_index]\n",
    "        train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "\n",
    "        tpr, fpr, precision, recall, f1, accuracy = evaluate_ids(train_data, train_labels, test_data, test_labels)\n",
    "        tprs.append(tpr)\n",
    "        fprs.append(fpr)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    mean_tpr = np.mean(tprs)\n",
    "    mean_fpr = np.mean(fprs)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "\n",
    "    print(\"Mean True Positive Rate (TPR):\", mean_tpr)\n",
    "    print(\"Mean False Positive Rate (FPR):\", mean_fpr)\n",
    "    print(\"Mean Precision:\", mean_precision)\n",
    "    print(\"Mean Recall:\", mean_recall)\n",
    "    print(\"Mean F1 Score:\", mean_f1)\n",
    "    print(\"Mean Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b8b52d-7adb-4fa3-adac-e3fd5679ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_ossec_alerts(log_file):\n",
    "    if not os.path.exists(log_file):\n",
    "        print(f\"Log file '{log_file}' does not exist.\")\n",
    "        return []\n",
    "\n",
    "    alerts = []\n",
    "    with open(log_file, 'r') as file:\n",
    "        for line in file:\n",
    "            alerts.append(line.strip())\n",
    "    return alerts\n",
    "\n",
    "def evaluate_performance(alerts):\n",
    "    true_positives = sum(1 for alert in alerts if \"attack detected\" in alert)\n",
    "    false_positives = sum(1 for alert in alerts if \"false alarm\" in alert)\n",
    "    false_negatives = sum(1 for alert in alerts if \"missed attack\" in alert)\n",
    "    total_attacks = true_positives + false_negatives\n",
    "    total_normal = false_positives + sum(1 for alert in alerts if \"normal\" in alert)\n",
    "\n",
    "    detection_rate = true_positives / total_attacks if total_attacks else 0\n",
    "    false_positive_rate = false_positives / total_normal if total_normal else 0\n",
    "    false_negative_rate = false_negatives / total_attacks if total_attacks else 0\n",
    "    false_alarm_rate = false_positives / (false_positives + true_positives) if (false_positives + true_positives) else 0\n",
    "\n",
    "    return {\n",
    "        \"Detection Rate (DR)\": detection_rate,\n",
    "        \"False Positive Rate (FPR)\": false_positive_rate,\n",
    "        \"False Negative Rate (FNR)\": false_negative_rate,\n",
    "        \"False Alarm Rate (FAR)\": false_alarm_rate\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    alerts_log = '/var/ossec/logs/alerts/alerts.log'\n",
    "    alerts = parse_ossec_alerts(alerts_log)\n",
    "    if alerts:\n",
    "        metrics = evaluate_performance(alerts)\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value}\")\n",
    "    else:\n",
    "        print(\"No alerts to evaluate.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
